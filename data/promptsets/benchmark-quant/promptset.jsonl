{"prompt_id": "bq-m-001", "prompt": "Calculate 91 * 24.", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["2184"], "expected_format": null, "target_output_tokens": 100, "bucket": "medium", "category": "math", "split": null, "metadata": null}
{"prompt_id": "bq-m-002", "prompt": "Calculate 13 * 45.", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["585"], "expected_format": null, "target_output_tokens": 100, "bucket": "medium", "category": "math", "split": null, "metadata": null}
{"prompt_id": "bq-m-003", "prompt": "Calculate 41 * 38.", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["1558"], "expected_format": null, "target_output_tokens": 100, "bucket": "medium", "category": "math", "split": null, "metadata": null}
{"prompt_id": "bq-m-004", "prompt": "Calculate 27 * 23.", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["621"], "expected_format": null, "target_output_tokens": 100, "bucket": "medium", "category": "math", "split": null, "metadata": null}
{"prompt_id": "bq-m-005", "prompt": "Calculate 96 * 79.", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["7584"], "expected_format": null, "target_output_tokens": 100, "bucket": "medium", "category": "math", "split": null, "metadata": null}
{"prompt_id": "bq-m-006", "prompt": "Calculate 21 * 85.", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["1785"], "expected_format": null, "target_output_tokens": 100, "bucket": "medium", "category": "math", "split": null, "metadata": null}
{"prompt_id": "bq-m-007", "prompt": "Calculate 64 * 14.", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["896"], "expected_format": null, "target_output_tokens": 100, "bucket": "medium", "category": "math", "split": null, "metadata": null}
{"prompt_id": "bq-m-008", "prompt": "Calculate 13 * 21.", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["273"], "expected_format": null, "target_output_tokens": 100, "bucket": "medium", "category": "math", "split": null, "metadata": null}
{"prompt_id": "bq-m-009", "prompt": "Calculate 37 * 39.", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["1443"], "expected_format": null, "target_output_tokens": 100, "bucket": "medium", "category": "math", "split": null, "metadata": null}
{"prompt_id": "bq-m-010", "prompt": "Calculate 74 * 87.", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["6438"], "expected_format": null, "target_output_tokens": 100, "bucket": "medium", "category": "math", "split": null, "metadata": null}
{"prompt_id": "bq-m-011", "prompt": "What is 2^3?", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["8"], "expected_format": null, "target_output_tokens": 100, "bucket": "medium", "category": "math", "split": null, "metadata": null}
{"prompt_id": "bq-m-012", "prompt": "What is 8^3?", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["512"], "expected_format": null, "target_output_tokens": 100, "bucket": "medium", "category": "math", "split": null, "metadata": null}
{"prompt_id": "bq-m-013", "prompt": "What is 9^4?", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["6561"], "expected_format": null, "target_output_tokens": 100, "bucket": "medium", "category": "math", "split": null, "metadata": null}
{"prompt_id": "bq-m-014", "prompt": "What is 2^3?", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["8"], "expected_format": null, "target_output_tokens": 100, "bucket": "medium", "category": "math", "split": null, "metadata": null}
{"prompt_id": "bq-m-015", "prompt": "What is 8^4?", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["4096"], "expected_format": null, "target_output_tokens": 100, "bucket": "medium", "category": "math", "split": null, "metadata": null}
{"prompt_id": "bq-m-016", "prompt": "What is 6^3?", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["216"], "expected_format": null, "target_output_tokens": 100, "bucket": "medium", "category": "math", "split": null, "metadata": null}
{"prompt_id": "bq-m-017", "prompt": "What is 5^4?", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["625"], "expected_format": null, "target_output_tokens": 100, "bucket": "medium", "category": "math", "split": null, "metadata": null}
{"prompt_id": "bq-m-018", "prompt": "What is 3^2?", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["9"], "expected_format": null, "target_output_tokens": 100, "bucket": "medium", "category": "math", "split": null, "metadata": null}
{"prompt_id": "bq-m-019", "prompt": "What is 8^2?", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["64"], "expected_format": null, "target_output_tokens": 100, "bucket": "medium", "category": "math", "split": null, "metadata": null}
{"prompt_id": "bq-m-020", "prompt": "What is 7^4?", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["2401"], "expected_format": null, "target_output_tokens": 100, "bucket": "medium", "category": "math", "split": null, "metadata": null}
{"prompt_id": "bq-m-021", "prompt": "What is 718 divided by 10? Give the integer part.", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["71"], "expected_format": null, "target_output_tokens": 100, "bucket": "medium", "category": "math", "split": null, "metadata": null}
{"prompt_id": "bq-m-022", "prompt": "What is 926 divided by 3? Give the integer part.", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["308"], "expected_format": null, "target_output_tokens": 100, "bucket": "medium", "category": "math", "split": null, "metadata": null}
{"prompt_id": "bq-m-023", "prompt": "What is 847 divided by 16? Give the integer part.", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["52"], "expected_format": null, "target_output_tokens": 100, "bucket": "medium", "category": "math", "split": null, "metadata": null}
{"prompt_id": "bq-m-024", "prompt": "What is 649 divided by 5? Give the integer part.", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["129"], "expected_format": null, "target_output_tokens": 100, "bucket": "medium", "category": "math", "split": null, "metadata": null}
{"prompt_id": "bq-m-025", "prompt": "What is 487 divided by 4? Give the integer part.", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["121"], "expected_format": null, "target_output_tokens": 100, "bucket": "medium", "category": "math", "split": null, "metadata": null}
{"prompt_id": "bq-m-026", "prompt": "What is 665 divided by 11? Give the integer part.", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["60"], "expected_format": null, "target_output_tokens": 100, "bucket": "medium", "category": "math", "split": null, "metadata": null}
{"prompt_id": "bq-m-027", "prompt": "What is 949 divided by 13? Give the integer part.", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["73"], "expected_format": null, "target_output_tokens": 100, "bucket": "medium", "category": "math", "split": null, "metadata": null}
{"prompt_id": "bq-m-028", "prompt": "What is 691 divided by 8? Give the integer part.", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["86"], "expected_format": null, "target_output_tokens": 100, "bucket": "medium", "category": "math", "split": null, "metadata": null}
{"prompt_id": "bq-m-029", "prompt": "What is 821 divided by 4? Give the integer part.", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["205"], "expected_format": null, "target_output_tokens": 100, "bucket": "medium", "category": "math", "split": null, "metadata": null}
{"prompt_id": "bq-m-030", "prompt": "What is 146 divided by 9? Give the integer part.", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["16"], "expected_format": null, "target_output_tokens": 100, "bucket": "medium", "category": "math", "split": null, "metadata": null}
{"prompt_id": "bq-m-031", "prompt": "What is 30% of 180?", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["54"], "expected_format": null, "target_output_tokens": 100, "bucket": "medium", "category": "math", "split": null, "metadata": null}
{"prompt_id": "bq-m-032", "prompt": "What is 25% of 986?", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["246"], "expected_format": null, "target_output_tokens": 100, "bucket": "medium", "category": "math", "split": null, "metadata": null}
{"prompt_id": "bq-m-033", "prompt": "What is 15% of 488?", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["73"], "expected_format": null, "target_output_tokens": 100, "bucket": "medium", "category": "math", "split": null, "metadata": null}
{"prompt_id": "bq-m-034", "prompt": "What is 30% of 564?", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["169"], "expected_format": null, "target_output_tokens": 100, "bucket": "medium", "category": "math", "split": null, "metadata": null}
{"prompt_id": "bq-m-035", "prompt": "What is 40% of 266?", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["106"], "expected_format": null, "target_output_tokens": 100, "bucket": "medium", "category": "math", "split": null, "metadata": null}
{"prompt_id": "bq-m-036", "prompt": "What is 40% of 462?", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["184"], "expected_format": null, "target_output_tokens": 100, "bucket": "medium", "category": "math", "split": null, "metadata": null}
{"prompt_id": "bq-m-037", "prompt": "What is 25% of 786?", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["196"], "expected_format": null, "target_output_tokens": 100, "bucket": "medium", "category": "math", "split": null, "metadata": null}
{"prompt_id": "bq-m-038", "prompt": "What is 30% of 818?", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["245"], "expected_format": null, "target_output_tokens": 100, "bucket": "medium", "category": "math", "split": null, "metadata": null}
{"prompt_id": "bq-m-039", "prompt": "What is 15% of 722?", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["108"], "expected_format": null, "target_output_tokens": 100, "bucket": "medium", "category": "math", "split": null, "metadata": null}
{"prompt_id": "bq-m-040", "prompt": "What is 20% of 646?", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["129"], "expected_format": null, "target_output_tokens": 100, "bucket": "medium", "category": "math", "split": null, "metadata": null}
{"prompt_id": "bq-m-041", "prompt": "Calculate (9 + 7) * 16.", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["256"], "expected_format": null, "target_output_tokens": 100, "bucket": "medium", "category": "math", "split": null, "metadata": null}
{"prompt_id": "bq-m-042", "prompt": "Calculate (14 + 10) * 19.", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["456"], "expected_format": null, "target_output_tokens": 100, "bucket": "medium", "category": "math", "split": null, "metadata": null}
{"prompt_id": "bq-m-043", "prompt": "Calculate (9 + 12) * 3.", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["63"], "expected_format": null, "target_output_tokens": 100, "bucket": "medium", "category": "math", "split": null, "metadata": null}
{"prompt_id": "bq-m-044", "prompt": "Calculate (9 + 3) * 12.", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["144"], "expected_format": null, "target_output_tokens": 100, "bucket": "medium", "category": "math", "split": null, "metadata": null}
{"prompt_id": "bq-m-045", "prompt": "Calculate (14 + 10) * 4.", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["96"], "expected_format": null, "target_output_tokens": 100, "bucket": "medium", "category": "math", "split": null, "metadata": null}
{"prompt_id": "bq-m-046", "prompt": "Calculate (8 + 20) * 12.", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["336"], "expected_format": null, "target_output_tokens": 100, "bucket": "medium", "category": "math", "split": null, "metadata": null}
{"prompt_id": "bq-m-047", "prompt": "Calculate (8 + 17) * 14.", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["350"], "expected_format": null, "target_output_tokens": 100, "bucket": "medium", "category": "math", "split": null, "metadata": null}
{"prompt_id": "bq-m-048", "prompt": "Calculate (16 + 6) * 10.", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["220"], "expected_format": null, "target_output_tokens": 100, "bucket": "medium", "category": "math", "split": null, "metadata": null}
{"prompt_id": "bq-m-049", "prompt": "Calculate (6 + 9) * 19.", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["285"], "expected_format": null, "target_output_tokens": 100, "bucket": "medium", "category": "math", "split": null, "metadata": null}
{"prompt_id": "bq-m-050", "prompt": "Calculate (19 + 10) * 20.", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["580"], "expected_format": null, "target_output_tokens": 100, "bucket": "medium", "category": "math", "split": null, "metadata": null}
{"prompt_id": "bq-r-001", "prompt": "A bat and ball cost $1.10 total. The bat costs $1 more than the ball. How much does the ball cost?", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["0.05", "5 cents", "five cents"], "expected_format": null, "target_output_tokens": 200, "bucket": "medium", "category": "reasoning", "split": null, "metadata": null}
{"prompt_id": "bq-r-002", "prompt": "If all roses are flowers and some flowers fade quickly, can we conclude some roses fade quickly?", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["no", "cannot", "not necessarily"], "expected_format": null, "target_output_tokens": 200, "bucket": "medium", "category": "reasoning", "split": null, "metadata": null}
{"prompt_id": "bq-r-003", "prompt": "In a race you overtake the person in 2nd place. What position are you now in?", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["2nd", "second"], "expected_format": null, "target_output_tokens": 150, "bucket": "medium", "category": "reasoning", "split": null, "metadata": null}
{"prompt_id": "bq-r-004", "prompt": "If you have 6 apples and take away 4, how many do you have?", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["4"], "expected_format": null, "target_output_tokens": 100, "bucket": "medium", "category": "reasoning", "split": null, "metadata": null}
{"prompt_id": "bq-r-005", "prompt": "A farmer has 17 sheep. All but 9 die. How many are left?", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["9"], "expected_format": null, "target_output_tokens": 100, "bucket": "medium", "category": "reasoning", "split": null, "metadata": null}
{"prompt_id": "bq-r-006", "prompt": "How many times can you subtract 5 from 25?", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["once", "1", "one time"], "expected_format": null, "target_output_tokens": 150, "bucket": "medium", "category": "reasoning", "split": null, "metadata": null}
{"prompt_id": "bq-r-007", "prompt": "If a doctor gives you 3 pills and says take one every 30 minutes, how long do they last?", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["60", "1 hour", "one hour"], "expected_format": null, "target_output_tokens": 150, "bucket": "medium", "category": "reasoning", "split": null, "metadata": null}
{"prompt_id": "bq-r-008", "prompt": "Is it legal for a man to marry his widow's sister?", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["no", "dead", "cannot"], "expected_format": null, "target_output_tokens": 150, "bucket": "medium", "category": "reasoning", "split": null, "metadata": null}
{"prompt_id": "bq-r-009", "prompt": "If there are 3 apples and you take away 2, how many apples do YOU have?", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["2"], "expected_format": null, "target_output_tokens": 100, "bucket": "medium", "category": "reasoning", "split": null, "metadata": null}
{"prompt_id": "bq-r-010", "prompt": "A clerk at a butcher shop is 5 ft 10 in tall. What does he weigh?", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["meat"], "expected_format": null, "target_output_tokens": 150, "bucket": "medium", "category": "reasoning", "split": null, "metadata": null}
{"prompt_id": "bq-r-011", "prompt": "If you rearrange the letters CIFAIPC, you get the name of a(n)?", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["ocean", "Pacific"], "expected_format": null, "target_output_tokens": 100, "bucket": "medium", "category": "reasoning", "split": null, "metadata": null}
{"prompt_id": "bq-r-012", "prompt": "Before Mount Everest was discovered, what was the tallest mountain on Earth?", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["Everest", "still"], "expected_format": null, "target_output_tokens": 200, "bucket": "medium", "category": "reasoning", "split": null, "metadata": null}
{"prompt_id": "bq-r-013", "prompt": "Some months have 30 days, some have 31. How many months have 28 days?", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["12", "all", "every"], "expected_format": null, "target_output_tokens": 150, "bucket": "medium", "category": "reasoning", "split": null, "metadata": null}
{"prompt_id": "bq-r-014", "prompt": "A train leaves at 9am going 60mph. Another leaves at 10am going 80mph. When does the second catch the first?", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["1", "pm", "noon"], "expected_format": null, "target_output_tokens": 300, "bucket": "medium", "category": "reasoning", "split": null, "metadata": null}
{"prompt_id": "bq-r-015", "prompt": "You are in a dark room with a candle, a wood stove, and a gas lamp. You only have one match. What do you light first?", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["match"], "expected_format": null, "target_output_tokens": 150, "bucket": "medium", "category": "reasoning", "split": null, "metadata": null}
{"prompt_id": "bq-r-016", "prompt": "How far can a dog run into the woods?", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["halfway", "half"], "expected_format": null, "target_output_tokens": 100, "bucket": "medium", "category": "reasoning", "split": null, "metadata": null}
{"prompt_id": "bq-r-017", "prompt": "If 2 is company and 3 is a crowd, what are 4 and 5?", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["9", "nine"], "expected_format": null, "target_output_tokens": 100, "bucket": "medium", "category": "reasoning", "split": null, "metadata": null}
{"prompt_id": "bq-r-018", "prompt": "Why are 1968 pennies worth more than 1967 pennies?", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["one more", "extra", "1968"], "expected_format": null, "target_output_tokens": 200, "bucket": "medium", "category": "reasoning", "split": null, "metadata": null}
{"prompt_id": "bq-r-019", "prompt": "What weighs more, a pound of feathers or a pound of bricks?", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["same", "equal", "neither"], "expected_format": null, "target_output_tokens": 150, "bucket": "medium", "category": "reasoning", "split": null, "metadata": null}
{"prompt_id": "bq-r-020", "prompt": "If a plane crashes on the border of US and Canada, where do you bury the survivors?", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["don't", "alive", "survivors"], "expected_format": null, "target_output_tokens": 150, "bucket": "medium", "category": "reasoning", "split": null, "metadata": null}
{"prompt_id": "bq-r-021", "prompt": "Three people each order a pizza. The waiter brings 3. How many pizzas are there?", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["3", "three"], "expected_format": null, "target_output_tokens": 100, "bucket": "medium", "category": "reasoning", "split": null, "metadata": null}
{"prompt_id": "bq-r-022", "prompt": "What comes next: 2, 6, 12, 20, 30, ?", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["42"], "expected_format": null, "target_output_tokens": 150, "bucket": "medium", "category": "reasoning", "split": null, "metadata": null}
{"prompt_id": "bq-r-023", "prompt": "What comes next: 1, 1, 2, 3, 5, 8, ?", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["13"], "expected_format": null, "target_output_tokens": 100, "bucket": "medium", "category": "reasoning", "split": null, "metadata": null}
{"prompt_id": "bq-r-024", "prompt": "If you have a 3-gallon jug and a 5-gallon jug, how do you measure 4 gallons?", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["fill", "pour"], "expected_format": null, "target_output_tokens": 300, "bucket": "medium", "category": "reasoning", "split": null, "metadata": null}
{"prompt_id": "bq-r-025", "prompt": "You see a boat filled with people but there is not a single person on board. How?", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["married", "couples", "all married"], "expected_format": null, "target_output_tokens": 150, "bucket": "medium", "category": "reasoning", "split": null, "metadata": null}
{"prompt_id": "bq-r-026", "prompt": "A man builds a house with all 4 sides facing south. A bear walks by. What color is the bear?", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["white", "polar"], "expected_format": null, "target_output_tokens": 150, "bucket": "medium", "category": "reasoning", "split": null, "metadata": null}
{"prompt_id": "bq-r-027", "prompt": "I speak without a mouth and hear without ears. I have no body, but I come alive with the wind. What am I?", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["echo"], "expected_format": null, "target_output_tokens": 100, "bucket": "medium", "category": "reasoning", "split": null, "metadata": null}
{"prompt_id": "bq-r-028", "prompt": "What has keys but no locks, space but no room, you can enter but can't go inside?", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["keyboard"], "expected_format": null, "target_output_tokens": 100, "bucket": "medium", "category": "reasoning", "split": null, "metadata": null}
{"prompt_id": "bq-r-029", "prompt": "What has a head and a tail but no body?", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["coin"], "expected_format": null, "target_output_tokens": 100, "bucket": "medium", "category": "reasoning", "split": null, "metadata": null}
{"prompt_id": "bq-r-030", "prompt": "The more you take, the more you leave behind. What am I?", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["footsteps", "steps"], "expected_format": null, "target_output_tokens": 100, "bucket": "medium", "category": "reasoning", "split": null, "metadata": null}
{"prompt_id": "bq-r-031", "prompt": "What has cities but no houses, forests but no trees, water but no fish?", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["map"], "expected_format": null, "target_output_tokens": 100, "bucket": "medium", "category": "reasoning", "split": null, "metadata": null}
{"prompt_id": "bq-r-032", "prompt": "If two's company and three's a crowd, what is four and five?", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["9", "nine"], "expected_format": null, "target_output_tokens": 100, "bucket": "medium", "category": "reasoning", "split": null, "metadata": null}
{"prompt_id": "bq-r-033", "prompt": "A cowboy rides into town on Friday. He stays 3 days and leaves on Friday. How?", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["horse", "named Friday"], "expected_format": null, "target_output_tokens": 200, "bucket": "medium", "category": "reasoning", "split": null, "metadata": null}
{"prompt_id": "bq-r-034", "prompt": "What gets wetter the more it dries?", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["towel"], "expected_format": null, "target_output_tokens": 100, "bucket": "medium", "category": "reasoning", "split": null, "metadata": null}
{"prompt_id": "bq-r-035", "prompt": "What can travel around the world while staying in a corner?", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["stamp"], "expected_format": null, "target_output_tokens": 100, "bucket": "medium", "category": "reasoning", "split": null, "metadata": null}
{"prompt_id": "bq-r-036", "prompt": "If 5 machines take 5 minutes to make 5 widgets, how long for 100 machines to make 100 widgets?", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["5"], "expected_format": null, "target_output_tokens": 200, "bucket": "medium", "category": "reasoning", "split": null, "metadata": null}
{"prompt_id": "bq-r-037", "prompt": "There are 5 houses in 5 colors. The English person lives in the red house. Who owns the fish?", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["German"], "expected_format": null, "target_output_tokens": 400, "bucket": "long", "category": "reasoning", "split": null, "metadata": null}
{"prompt_id": "bq-r-038", "prompt": "A woman shoots her husband, then holds him under water for 5 minutes. Then she hangs him. But 5 minutes later they enjoy dinner. How?", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["photograph", "picture", "photo"], "expected_format": null, "target_output_tokens": 200, "bucket": "medium", "category": "reasoning", "split": null, "metadata": null}
{"prompt_id": "bq-r-039", "prompt": "What occurs once in a minute, twice in a moment, but never in a thousand years?", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["m", "letter"], "expected_format": null, "target_output_tokens": 100, "bucket": "medium", "category": "reasoning", "split": null, "metadata": null}
{"prompt_id": "bq-r-040", "prompt": "I am not alive but I grow. I have no lungs but I need air. What am I?", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["fire"], "expected_format": null, "target_output_tokens": 100, "bucket": "medium", "category": "reasoning", "split": null, "metadata": null}
{"prompt_id": "bq-r-041", "prompt": "What can be broken without being held?", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["promise"], "expected_format": null, "target_output_tokens": 100, "bucket": "medium", "category": "reasoning", "split": null, "metadata": null}
{"prompt_id": "bq-r-042", "prompt": "Complete the pattern: 1, 4, 9, 16, 25, ?", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["36"], "expected_format": null, "target_output_tokens": 100, "bucket": "medium", "category": "reasoning", "split": null, "metadata": null}
{"prompt_id": "bq-r-043", "prompt": "Complete the pattern: 2, 3, 5, 7, 11, 13, ?", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["17"], "expected_format": null, "target_output_tokens": 100, "bucket": "medium", "category": "reasoning", "split": null, "metadata": null}
{"prompt_id": "bq-r-044", "prompt": "If you multiply all digits from 0-9, what is the result?", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["0", "zero"], "expected_format": null, "target_output_tokens": 100, "bucket": "medium", "category": "reasoning", "split": null, "metadata": null}
{"prompt_id": "bq-r-045", "prompt": "What is the next prime number after 97?", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["101"], "expected_format": null, "target_output_tokens": 100, "bucket": "medium", "category": "reasoning", "split": null, "metadata": null}
{"prompt_id": "bq-r-046", "prompt": "A lily pad doubles in size each day. On day 48 it covers the lake. On what day was it half covered?", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["47"], "expected_format": null, "target_output_tokens": 150, "bucket": "medium", "category": "reasoning", "split": null, "metadata": null}
{"prompt_id": "bq-r-047", "prompt": "You have 12 balls, one is heavier. With a balance scale, what is the minimum weighings to find it?", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["3", "three"], "expected_format": null, "target_output_tokens": 200, "bucket": "medium", "category": "reasoning", "split": null, "metadata": null}
{"prompt_id": "bq-r-048", "prompt": "How many squares are on a standard 8x8 chessboard?", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["204"], "expected_format": null, "target_output_tokens": 200, "bucket": "medium", "category": "reasoning", "split": null, "metadata": null}
{"prompt_id": "bq-r-049", "prompt": "What is the sum of integers from 1 to 100?", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["5050"], "expected_format": null, "target_output_tokens": 100, "bucket": "medium", "category": "reasoning", "split": null, "metadata": null}
{"prompt_id": "bq-r-050", "prompt": "If you flip a fair coin 3 times, what is the probability of getting exactly 2 heads?", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["3/8", "0.375", "37.5"], "expected_format": null, "target_output_tokens": 200, "bucket": "medium", "category": "reasoning", "split": null, "metadata": null}
{"prompt_id": "bq-c-001", "prompt": "Write a Python function to compute factorial(n) iteratively.", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["def", "factorial", "return"], "expected_format": null, "target_output_tokens": 200, "bucket": "medium", "category": "code", "split": null, "metadata": null}
{"prompt_id": "bq-c-002", "prompt": "Write a Python function to check if a number is prime.", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["def", "prime", "return"], "expected_format": null, "target_output_tokens": 200, "bucket": "medium", "category": "code", "split": null, "metadata": null}
{"prompt_id": "bq-c-003", "prompt": "Write a Python function to reverse a linked list.", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["def", "next", "return"], "expected_format": null, "target_output_tokens": 300, "bucket": "medium", "category": "code", "split": null, "metadata": null}
{"prompt_id": "bq-c-004", "prompt": "Write a Python function to find the GCD of two numbers.", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["def", "gcd", "return"], "expected_format": null, "target_output_tokens": 200, "bucket": "medium", "category": "code", "split": null, "metadata": null}
{"prompt_id": "bq-c-005", "prompt": "Write a Python function to implement binary search.", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["def", "binary", "return"], "expected_format": null, "target_output_tokens": 250, "bucket": "medium", "category": "code", "split": null, "metadata": null}
{"prompt_id": "bq-c-006", "prompt": "Write a Python function to merge two sorted lists.", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["def", "merge", "return"], "expected_format": null, "target_output_tokens": 250, "bucket": "medium", "category": "code", "split": null, "metadata": null}
{"prompt_id": "bq-c-007", "prompt": "Write a Python function to check if a string is a palindrome.", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["def", "palindrome", "return"], "expected_format": null, "target_output_tokens": 200, "bucket": "medium", "category": "code", "split": null, "metadata": null}
{"prompt_id": "bq-c-008", "prompt": "Write a Python function to flatten a nested list.", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["def", "flatten", "return"], "expected_format": null, "target_output_tokens": 250, "bucket": "medium", "category": "code", "split": null, "metadata": null}
{"prompt_id": "bq-c-009", "prompt": "Write a Python function to compute the nth Fibonacci number using memoization.", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["def", "fib", "return"], "expected_format": null, "target_output_tokens": 250, "bucket": "medium", "category": "code", "split": null, "metadata": null}
{"prompt_id": "bq-c-010", "prompt": "Write a Python function to find all permutations of a string.", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["def", "perm", "return"], "expected_format": null, "target_output_tokens": 300, "bucket": "medium", "category": "code", "split": null, "metadata": null}
{"prompt_id": "bq-c-011", "prompt": "Write a SQL query to find the top 5 customers by total order amount.", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["SELECT", "ORDER BY", "LIMIT"], "expected_format": null, "target_output_tokens": 200, "bucket": "medium", "category": "code", "split": null, "metadata": null}
{"prompt_id": "bq-c-012", "prompt": "Write a SQL query to find duplicate email addresses in a users table.", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["SELECT", "GROUP BY", "HAVING"], "expected_format": null, "target_output_tokens": 200, "bucket": "medium", "category": "code", "split": null, "metadata": null}
{"prompt_id": "bq-c-013", "prompt": "Write a SQL query joining orders with customers where order total exceeds 1000.", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["SELECT", "JOIN", "WHERE"], "expected_format": null, "target_output_tokens": 200, "bucket": "medium", "category": "code", "split": null, "metadata": null}
{"prompt_id": "bq-c-014", "prompt": "Write a SQL query to find the second-highest salary.", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["SELECT", "salary"], "expected_format": null, "target_output_tokens": 200, "bucket": "medium", "category": "code", "split": null, "metadata": null}
{"prompt_id": "bq-c-015", "prompt": "Write a SQL query to calculate a running total of daily sales.", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["SELECT", "SUM", "OVER"], "expected_format": null, "target_output_tokens": 200, "bucket": "medium", "category": "code", "split": null, "metadata": null}
{"prompt_id": "bq-c-016", "prompt": "Write a Python class implementing a stack with push, pop, and peek.", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["class", "push", "pop"], "expected_format": null, "target_output_tokens": 300, "bucket": "medium", "category": "code", "split": null, "metadata": null}
{"prompt_id": "bq-c-017", "prompt": "Write a Python class implementing a queue using two stacks.", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["class", "enqueue", "dequeue"], "expected_format": null, "target_output_tokens": 300, "bucket": "medium", "category": "code", "split": null, "metadata": null}
{"prompt_id": "bq-c-018", "prompt": "Write a Python function for depth-first search on a graph.", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["def", "dfs", "visited"], "expected_format": null, "target_output_tokens": 300, "bucket": "medium", "category": "code", "split": null, "metadata": null}
{"prompt_id": "bq-c-019", "prompt": "Write a Python function for breadth-first search on a graph.", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["def", "bfs", "queue"], "expected_format": null, "target_output_tokens": 300, "bucket": "medium", "category": "code", "split": null, "metadata": null}
{"prompt_id": "bq-c-020", "prompt": "Write a Python function to find the longest common substring of two strings.", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["def", "common", "return"], "expected_format": null, "target_output_tokens": 300, "bucket": "medium", "category": "code", "split": null, "metadata": null}
{"prompt_id": "bq-c-021", "prompt": "Write a Python decorator that logs function execution time.", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["def", "wrapper", "time"], "expected_format": null, "target_output_tokens": 250, "bucket": "medium", "category": "code", "split": null, "metadata": null}
{"prompt_id": "bq-c-022", "prompt": "Write a Python function to validate an email address using regex.", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["def", "re", "return"], "expected_format": null, "target_output_tokens": 200, "bucket": "medium", "category": "code", "split": null, "metadata": null}
{"prompt_id": "bq-c-023", "prompt": "Write a Python function to read a CSV file and return a list of dicts.", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["def", "csv", "return"], "expected_format": null, "target_output_tokens": 250, "bucket": "medium", "category": "code", "split": null, "metadata": null}
{"prompt_id": "bq-c-024", "prompt": "Write a Python context manager for database connections.", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["class", "__enter__", "__exit__"], "expected_format": null, "target_output_tokens": 300, "bucket": "medium", "category": "code", "split": null, "metadata": null}
{"prompt_id": "bq-c-025", "prompt": "Write a Python async function that fetches a URL with aiohttp.", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["async", "def", "await"], "expected_format": null, "target_output_tokens": 250, "bucket": "medium", "category": "code", "split": null, "metadata": null}
{"prompt_id": "bq-c-026", "prompt": "Write a Python function to implement quicksort.", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["def", "quicksort", "pivot"], "expected_format": null, "target_output_tokens": 300, "bucket": "medium", "category": "code", "split": null, "metadata": null}
{"prompt_id": "bq-c-027", "prompt": "Write a Python function to implement mergesort.", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["def", "mergesort", "merge"], "expected_format": null, "target_output_tokens": 300, "bucket": "medium", "category": "code", "split": null, "metadata": null}
{"prompt_id": "bq-c-028", "prompt": "Write a Python function to detect a cycle in a linked list.", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["def", "cycle", "return"], "expected_format": null, "target_output_tokens": 250, "bucket": "medium", "category": "code", "split": null, "metadata": null}
{"prompt_id": "bq-c-029", "prompt": "Write a Python function to find the kth largest element in an array.", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["def", "return"], "expected_format": null, "target_output_tokens": 250, "bucket": "medium", "category": "code", "split": null, "metadata": null}
{"prompt_id": "bq-c-030", "prompt": "Write a Python function to implement a trie data structure insert and search.", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["class", "insert", "search"], "expected_format": null, "target_output_tokens": 400, "bucket": "long", "category": "code", "split": null, "metadata": null}
{"prompt_id": "bq-c-031", "prompt": "Write a Python function to serialize and deserialize a binary tree.", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["def", "serialize", "deserialize"], "expected_format": null, "target_output_tokens": 400, "bucket": "long", "category": "code", "split": null, "metadata": null}
{"prompt_id": "bq-c-032", "prompt": "Write a Python function to find the longest increasing subsequence.", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["def", "longest", "return"], "expected_format": null, "target_output_tokens": 300, "bucket": "medium", "category": "code", "split": null, "metadata": null}
{"prompt_id": "bq-c-033", "prompt": "Write a Python generator that yields prime numbers.", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["def", "yield", "prime"], "expected_format": null, "target_output_tokens": 250, "bucket": "medium", "category": "code", "split": null, "metadata": null}
{"prompt_id": "bq-c-034", "prompt": "Write a Python function to implement LRU cache.", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["class", "get", "put"], "expected_format": null, "target_output_tokens": 400, "bucket": "long", "category": "code", "split": null, "metadata": null}
{"prompt_id": "bq-c-035", "prompt": "Write a Python function to validate balanced parentheses.", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["def", "stack", "return"], "expected_format": null, "target_output_tokens": 200, "bucket": "medium", "category": "code", "split": null, "metadata": null}
{"prompt_id": "bq-c-036", "prompt": "Write a Python function to convert Roman numerals to integers.", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["def", "roman", "return"], "expected_format": null, "target_output_tokens": 300, "bucket": "medium", "category": "code", "split": null, "metadata": null}
{"prompt_id": "bq-c-037", "prompt": "Write a Python function to implement matrix multiplication.", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["def", "matrix", "return"], "expected_format": null, "target_output_tokens": 300, "bucket": "medium", "category": "code", "split": null, "metadata": null}
{"prompt_id": "bq-c-038", "prompt": "Write a Python function to find all anagrams of a word in a list.", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["def", "anagram", "return"], "expected_format": null, "target_output_tokens": 250, "bucket": "medium", "category": "code", "split": null, "metadata": null}
{"prompt_id": "bq-c-039", "prompt": "Write a Python function to implement Dijkstra's shortest path.", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["def", "dijkstra", "distance"], "expected_format": null, "target_output_tokens": 400, "bucket": "long", "category": "code", "split": null, "metadata": null}
{"prompt_id": "bq-c-040", "prompt": "Write a Python function to implement a min-heap.", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["class", "insert", "extract"], "expected_format": null, "target_output_tokens": 400, "bucket": "long", "category": "code", "split": null, "metadata": null}
{"prompt_id": "bq-c-041", "prompt": "Write a Bash one-liner to find the 10 largest files in /var/log.", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["find", "sort", "head"], "expected_format": null, "target_output_tokens": 150, "bucket": "medium", "category": "code", "split": null, "metadata": null}
{"prompt_id": "bq-c-042", "prompt": "Write a Python function to count word frequencies in a text.", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["def", "count", "return"], "expected_format": null, "target_output_tokens": 200, "bucket": "medium", "category": "code", "split": null, "metadata": null}
{"prompt_id": "bq-c-043", "prompt": "Write a Python function to convert a decimal to binary.", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["def", "binary", "return"], "expected_format": null, "target_output_tokens": 200, "bucket": "medium", "category": "code", "split": null, "metadata": null}
{"prompt_id": "bq-c-044", "prompt": "Write a Python function to implement the Sieve of Eratosthenes.", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["def", "sieve", "prime"], "expected_format": null, "target_output_tokens": 250, "bucket": "medium", "category": "code", "split": null, "metadata": null}
{"prompt_id": "bq-c-045", "prompt": "Write a Python function to check if two strings are anagrams.", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["def", "anagram", "return"], "expected_format": null, "target_output_tokens": 200, "bucket": "medium", "category": "code", "split": null, "metadata": null}
{"prompt_id": "bq-c-046", "prompt": "Write a Python function to rotate a matrix 90 degrees clockwise.", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["def", "rotate", "matrix"], "expected_format": null, "target_output_tokens": 300, "bucket": "medium", "category": "code", "split": null, "metadata": null}
{"prompt_id": "bq-c-047", "prompt": "Write a Python function to find the median of two sorted arrays.", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["def", "median", "return"], "expected_format": null, "target_output_tokens": 300, "bucket": "medium", "category": "code", "split": null, "metadata": null}
{"prompt_id": "bq-c-048", "prompt": "Write a Python function to implement a bloom filter.", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["class", "add", "contains"], "expected_format": null, "target_output_tokens": 400, "bucket": "long", "category": "code", "split": null, "metadata": null}
{"prompt_id": "bq-c-049", "prompt": "Write a Python function to parse a JSON string without using json module.", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["def", "parse", "return"], "expected_format": null, "target_output_tokens": 400, "bucket": "long", "category": "code", "split": null, "metadata": null}
{"prompt_id": "bq-c-050", "prompt": "Write a Python function to calculate Levenshtein distance.", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["def", "distance", "return"], "expected_format": null, "target_output_tokens": 300, "bucket": "medium", "category": "code", "split": null, "metadata": null}
{"prompt_id": "bq-f-001", "prompt": "What is the chemical symbol for gold?", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["Au"], "expected_format": null, "target_output_tokens": 50, "bucket": "short", "category": "factual", "split": null, "metadata": null}
{"prompt_id": "bq-f-002", "prompt": "What planet is closest to the Sun?", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["Mercury"], "expected_format": null, "target_output_tokens": 50, "bucket": "short", "category": "factual", "split": null, "metadata": null}
{"prompt_id": "bq-f-003", "prompt": "What is the speed of light in meters per second?", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["299792458", "3", "10^8"], "expected_format": null, "target_output_tokens": 100, "bucket": "medium", "category": "factual", "split": null, "metadata": null}
{"prompt_id": "bq-f-004", "prompt": "Who wrote Romeo and Juliet?", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["Shakespeare"], "expected_format": null, "target_output_tokens": 50, "bucket": "short", "category": "factual", "split": null, "metadata": null}
{"prompt_id": "bq-f-005", "prompt": "What is the largest ocean on Earth?", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["Pacific"], "expected_format": null, "target_output_tokens": 50, "bucket": "short", "category": "factual", "split": null, "metadata": null}
{"prompt_id": "bq-f-006", "prompt": "What year did World War II end?", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["1945"], "expected_format": null, "target_output_tokens": 50, "bucket": "short", "category": "factual", "split": null, "metadata": null}
{"prompt_id": "bq-f-007", "prompt": "What is the powerhouse of the cell?", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["mitochondria"], "expected_format": null, "target_output_tokens": 50, "bucket": "short", "category": "factual", "split": null, "metadata": null}
{"prompt_id": "bq-f-008", "prompt": "What is the atomic number of carbon?", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["6"], "expected_format": null, "target_output_tokens": 50, "bucket": "short", "category": "factual", "split": null, "metadata": null}
{"prompt_id": "bq-f-009", "prompt": "What is the smallest prime number?", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["2"], "expected_format": null, "target_output_tokens": 50, "bucket": "short", "category": "factual", "split": null, "metadata": null}
{"prompt_id": "bq-f-010", "prompt": "Who painted the Mona Lisa?", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["Leonardo", "Vinci"], "expected_format": null, "target_output_tokens": 50, "bucket": "short", "category": "factual", "split": null, "metadata": null}
{"prompt_id": "bq-f-011", "prompt": "What is the capital of Australia?", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["Canberra"], "expected_format": null, "target_output_tokens": 50, "bucket": "short", "category": "factual", "split": null, "metadata": null}
{"prompt_id": "bq-f-012", "prompt": "What is the half-life of Carbon-14?", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["5730", "5700"], "expected_format": null, "target_output_tokens": 100, "bucket": "medium", "category": "factual", "split": null, "metadata": null}
{"prompt_id": "bq-f-013", "prompt": "What is Avogadro's number?", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["6.022", "10^23"], "expected_format": null, "target_output_tokens": 100, "bucket": "medium", "category": "factual", "split": null, "metadata": null}
{"prompt_id": "bq-f-014", "prompt": "What is the boiling point of water in Celsius?", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["100"], "expected_format": null, "target_output_tokens": 50, "bucket": "short", "category": "factual", "split": null, "metadata": null}
{"prompt_id": "bq-f-015", "prompt": "What is the PH of pure water?", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["7"], "expected_format": null, "target_output_tokens": 50, "bucket": "short", "category": "factual", "split": null, "metadata": null}
{"prompt_id": "bq-f-016", "prompt": "What gas do plants absorb from the atmosphere?", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["CO2", "carbon dioxide"], "expected_format": null, "target_output_tokens": 50, "bucket": "short", "category": "factual", "split": null, "metadata": null}
{"prompt_id": "bq-f-017", "prompt": "What is the most abundant element in the universe?", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["hydrogen"], "expected_format": null, "target_output_tokens": 50, "bucket": "short", "category": "factual", "split": null, "metadata": null}
{"prompt_id": "bq-f-018", "prompt": "Who developed the theory of general relativity?", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["Einstein"], "expected_format": null, "target_output_tokens": 50, "bucket": "short", "category": "factual", "split": null, "metadata": null}
{"prompt_id": "bq-f-019", "prompt": "What is the SI unit of electric current?", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["ampere", "amp"], "expected_format": null, "target_output_tokens": 50, "bucket": "short", "category": "factual", "split": null, "metadata": null}
{"prompt_id": "bq-f-020", "prompt": "What is the charge of an electron?", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["negative", "-1.6"], "expected_format": null, "target_output_tokens": 100, "bucket": "medium", "category": "factual", "split": null, "metadata": null}
{"prompt_id": "bq-f-021", "prompt": "Who discovered penicillin?", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["Fleming"], "expected_format": null, "target_output_tokens": 50, "bucket": "short", "category": "factual", "split": null, "metadata": null}
{"prompt_id": "bq-f-022", "prompt": "What is the formula for the area of a circle?", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["pi", "r^2", "r**2"], "expected_format": null, "target_output_tokens": 100, "bucket": "medium", "category": "factual", "split": null, "metadata": null}
{"prompt_id": "bq-f-023", "prompt": "What is the longest river in the world?", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["Nile", "Amazon"], "expected_format": null, "target_output_tokens": 50, "bucket": "short", "category": "factual", "split": null, "metadata": null}
{"prompt_id": "bq-f-024", "prompt": "What is the largest desert in the world?", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["Sahara", "Antarctic"], "expected_format": null, "target_output_tokens": 100, "bucket": "medium", "category": "factual", "split": null, "metadata": null}
{"prompt_id": "bq-f-025", "prompt": "Who invented the telephone?", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["Bell"], "expected_format": null, "target_output_tokens": 50, "bucket": "short", "category": "factual", "split": null, "metadata": null}
{"prompt_id": "bq-f-026", "prompt": "What is the freezing point of water in Fahrenheit?", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["32"], "expected_format": null, "target_output_tokens": 50, "bucket": "short", "category": "factual", "split": null, "metadata": null}
{"prompt_id": "bq-f-027", "prompt": "What is the molecular formula for glucose?", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["C6H12O6"], "expected_format": null, "target_output_tokens": 100, "bucket": "medium", "category": "factual", "split": null, "metadata": null}
{"prompt_id": "bq-f-028", "prompt": "What element has the symbol Fe?", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["iron"], "expected_format": null, "target_output_tokens": 50, "bucket": "short", "category": "factual", "split": null, "metadata": null}
{"prompt_id": "bq-f-029", "prompt": "How many chromosomes do humans have?", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["46"], "expected_format": null, "target_output_tokens": 50, "bucket": "short", "category": "factual", "split": null, "metadata": null}
{"prompt_id": "bq-f-030", "prompt": "What is the distance from Earth to the Moon in kilometers?", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["384", "400"], "expected_format": null, "target_output_tokens": 100, "bucket": "medium", "category": "factual", "split": null, "metadata": null}
{"prompt_id": "bq-f-031", "prompt": "What is the tallest animal in the world?", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["giraffe"], "expected_format": null, "target_output_tokens": 50, "bucket": "short", "category": "factual", "split": null, "metadata": null}
{"prompt_id": "bq-f-032", "prompt": "What year was the Declaration of Independence signed?", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["1776"], "expected_format": null, "target_output_tokens": 50, "bucket": "short", "category": "factual", "split": null, "metadata": null}
{"prompt_id": "bq-f-033", "prompt": "What is the chemical formula for table salt?", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["NaCl"], "expected_format": null, "target_output_tokens": 50, "bucket": "short", "category": "factual", "split": null, "metadata": null}
{"prompt_id": "bq-f-034", "prompt": "What is the most abundant gas in Earth's atmosphere?", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["nitrogen"], "expected_format": null, "target_output_tokens": 50, "bucket": "short", "category": "factual", "split": null, "metadata": null}
{"prompt_id": "bq-f-035", "prompt": "What is the largest organ in the human body?", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["skin"], "expected_format": null, "target_output_tokens": 50, "bucket": "short", "category": "factual", "split": null, "metadata": null}
{"prompt_id": "bq-f-036", "prompt": "What is absolute zero in Celsius?", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["-273", "273.15"], "expected_format": null, "target_output_tokens": 100, "bucket": "medium", "category": "factual", "split": null, "metadata": null}
{"prompt_id": "bq-f-037", "prompt": "What is the Pythagorean theorem?", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["a^2", "b^2", "c^2"], "expected_format": null, "target_output_tokens": 100, "bucket": "medium", "category": "factual", "split": null, "metadata": null}
{"prompt_id": "bq-f-038", "prompt": "How many bones are in the adult human body?", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["206"], "expected_format": null, "target_output_tokens": 50, "bucket": "short", "category": "factual", "split": null, "metadata": null}
{"prompt_id": "bq-f-039", "prompt": "What is the speed of sound in air at sea level?", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["343", "340"], "expected_format": null, "target_output_tokens": 100, "bucket": "medium", "category": "factual", "split": null, "metadata": null}
{"prompt_id": "bq-f-040", "prompt": "What planet has the most moons?", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["Saturn", "Jupiter"], "expected_format": null, "target_output_tokens": 50, "bucket": "short", "category": "factual", "split": null, "metadata": null}
{"prompt_id": "bq-f-041", "prompt": "What is the chemical symbol for sodium?", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["Na"], "expected_format": null, "target_output_tokens": 50, "bucket": "short", "category": "factual", "split": null, "metadata": null}
{"prompt_id": "bq-f-042", "prompt": "What is the process by which plants make food from sunlight?", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["photosynthesis"], "expected_format": null, "target_output_tokens": 50, "bucket": "short", "category": "factual", "split": null, "metadata": null}
{"prompt_id": "bq-f-043", "prompt": "What is the hardest natural substance?", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["diamond"], "expected_format": null, "target_output_tokens": 50, "bucket": "short", "category": "factual", "split": null, "metadata": null}
{"prompt_id": "bq-f-044", "prompt": "What is the largest planet in our solar system?", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["Jupiter"], "expected_format": null, "target_output_tokens": 50, "bucket": "short", "category": "factual", "split": null, "metadata": null}
{"prompt_id": "bq-f-045", "prompt": "What is DNA an abbreviation for?", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["deoxyribonucleic"], "expected_format": null, "target_output_tokens": 100, "bucket": "medium", "category": "factual", "split": null, "metadata": null}
{"prompt_id": "bq-f-046", "prompt": "What is the currency of Japan?", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["yen"], "expected_format": null, "target_output_tokens": 50, "bucket": "short", "category": "factual", "split": null, "metadata": null}
{"prompt_id": "bq-f-047", "prompt": "Who was the first person to walk on the Moon?", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["Armstrong", "Neil"], "expected_format": null, "target_output_tokens": 50, "bucket": "short", "category": "factual", "split": null, "metadata": null}
{"prompt_id": "bq-f-048", "prompt": "What is the main component of the Sun?", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["hydrogen", "helium"], "expected_format": null, "target_output_tokens": 50, "bucket": "short", "category": "factual", "split": null, "metadata": null}
{"prompt_id": "bq-f-049", "prompt": "What is the acceleration due to gravity on Earth?", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["9.8", "9.81"], "expected_format": null, "target_output_tokens": 100, "bucket": "medium", "category": "factual", "split": null, "metadata": null}
{"prompt_id": "bq-f-050", "prompt": "How many elements are in the periodic table?", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": ["118"], "expected_format": null, "target_output_tokens": 50, "bucket": "short", "category": "factual", "split": null, "metadata": null}
{"prompt_id": "bq-l-001", "prompt": "Explain how a neural network learns through backpropagation. Include the chain rule and gradient descent.", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": null, "expected_format": null, "target_output_tokens": 500, "bucket": "long", "category": "long_form", "split": null, "metadata": null}
{"prompt_id": "bq-l-002", "prompt": "Describe the water cycle in detail, covering evaporation, condensation, precipitation, and collection.", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": null, "expected_format": null, "target_output_tokens": 400, "bucket": "long", "category": "long_form", "split": null, "metadata": null}
{"prompt_id": "bq-l-003", "prompt": "Write a detailed comparison of TCP and UDP protocols. Cover reliability, speed, and use cases.", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": null, "expected_format": null, "target_output_tokens": 500, "bucket": "long", "category": "long_form", "split": null, "metadata": null}
{"prompt_id": "bq-l-004", "prompt": "Explain the process of photosynthesis at the molecular level.", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": null, "expected_format": null, "target_output_tokens": 400, "bucket": "long", "category": "long_form", "split": null, "metadata": null}
{"prompt_id": "bq-l-005", "prompt": "Describe the architecture of a modern CPU including pipeline stages.", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": null, "expected_format": null, "target_output_tokens": 500, "bucket": "long", "category": "long_form", "split": null, "metadata": null}
{"prompt_id": "bq-l-006", "prompt": "Write a comprehensive overview of the causes of World War I.", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": null, "expected_format": null, "target_output_tokens": 500, "bucket": "long", "category": "long_form", "split": null, "metadata": null}
{"prompt_id": "bq-l-007", "prompt": "Explain how public-key cryptography works, including RSA.", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": null, "expected_format": null, "target_output_tokens": 500, "bucket": "long", "category": "long_form", "split": null, "metadata": null}
{"prompt_id": "bq-l-008", "prompt": "Describe the process of human digestion from mouth to intestine.", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": null, "expected_format": null, "target_output_tokens": 400, "bucket": "long", "category": "long_form", "split": null, "metadata": null}
{"prompt_id": "bq-l-009", "prompt": "Write a detailed explanation of how Docker containers work internally.", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": null, "expected_format": null, "target_output_tokens": 500, "bucket": "long", "category": "long_form", "split": null, "metadata": null}
{"prompt_id": "bq-l-010", "prompt": "Explain the economics of supply and demand with examples.", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": null, "expected_format": null, "target_output_tokens": 400, "bucket": "long", "category": "long_form", "split": null, "metadata": null}
{"prompt_id": "bq-l-011", "prompt": "Describe the theory of evolution by natural selection.", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": null, "expected_format": null, "target_output_tokens": 500, "bucket": "long", "category": "long_form", "split": null, "metadata": null}
{"prompt_id": "bq-l-012", "prompt": "Write a comprehensive guide to SQL JOINs with examples.", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": null, "expected_format": null, "target_output_tokens": 500, "bucket": "long", "category": "long_form", "split": null, "metadata": null}
{"prompt_id": "bq-l-013", "prompt": "Explain how a compiler transforms source code into machine code.", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": null, "expected_format": null, "target_output_tokens": 500, "bucket": "long", "category": "long_form", "split": null, "metadata": null}
{"prompt_id": "bq-l-014", "prompt": "Describe the greenhouse effect and its role in climate change.", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": null, "expected_format": null, "target_output_tokens": 400, "bucket": "long", "category": "long_form", "split": null, "metadata": null}
{"prompt_id": "bq-l-015", "prompt": "Write a detailed overview of HTTP/2 improvements over HTTP/1.1.", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": null, "expected_format": null, "target_output_tokens": 500, "bucket": "long", "category": "long_form", "split": null, "metadata": null}
{"prompt_id": "bq-l-016", "prompt": "Explain the CAP theorem in distributed systems with examples.", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": null, "expected_format": null, "target_output_tokens": 500, "bucket": "long", "category": "long_form", "split": null, "metadata": null}
{"prompt_id": "bq-l-017", "prompt": "Describe how vaccines work to provide immunity.", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": null, "expected_format": null, "target_output_tokens": 400, "bucket": "long", "category": "long_form", "split": null, "metadata": null}
{"prompt_id": "bq-l-018", "prompt": "Write a detailed explanation of Git branching strategies.", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": null, "expected_format": null, "target_output_tokens": 500, "bucket": "long", "category": "long_form", "split": null, "metadata": null}
{"prompt_id": "bq-l-019", "prompt": "Explain the difference between classical and quantum computing.", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": null, "expected_format": null, "target_output_tokens": 500, "bucket": "long", "category": "long_form", "split": null, "metadata": null}
{"prompt_id": "bq-l-020", "prompt": "Describe the electoral college system in the United States.", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": null, "expected_format": null, "target_output_tokens": 400, "bucket": "long", "category": "long_form", "split": null, "metadata": null}
{"prompt_id": "bq-l-021", "prompt": "Write a comprehensive overview of machine learning model evaluation metrics.", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": null, "expected_format": null, "target_output_tokens": 500, "bucket": "long", "category": "long_form", "split": null, "metadata": null}
{"prompt_id": "bq-l-022", "prompt": "Explain how DNS resolution works step by step.", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": null, "expected_format": null, "target_output_tokens": 400, "bucket": "long", "category": "long_form", "split": null, "metadata": null}
{"prompt_id": "bq-l-023", "prompt": "Describe the architecture of Kubernetes and its main components.", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": null, "expected_format": null, "target_output_tokens": 500, "bucket": "long", "category": "long_form", "split": null, "metadata": null}
{"prompt_id": "bq-l-024", "prompt": "Write a detailed comparison of NoSQL database types.", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": null, "expected_format": null, "target_output_tokens": 500, "bucket": "long", "category": "long_form", "split": null, "metadata": null}
{"prompt_id": "bq-l-025", "prompt": "Explain the principles of object-oriented programming.", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": null, "expected_format": null, "target_output_tokens": 400, "bucket": "long", "category": "long_form", "split": null, "metadata": null}
{"prompt_id": "bq-l-026", "prompt": "Describe how a blockchain achieves consensus.", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": null, "expected_format": null, "target_output_tokens": 500, "bucket": "long", "category": "long_form", "split": null, "metadata": null}
{"prompt_id": "bq-l-027", "prompt": "Write a comprehensive overview of RESTful API design principles.", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": null, "expected_format": null, "target_output_tokens": 500, "bucket": "long", "category": "long_form", "split": null, "metadata": null}
{"prompt_id": "bq-l-028", "prompt": "Explain the process of mitosis and meiosis in cell division.", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": null, "expected_format": null, "target_output_tokens": 500, "bucket": "long", "category": "long_form", "split": null, "metadata": null}
{"prompt_id": "bq-l-029", "prompt": "Describe how OAuth 2.0 authorization works.", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": null, "expected_format": null, "target_output_tokens": 500, "bucket": "long", "category": "long_form", "split": null, "metadata": null}
{"prompt_id": "bq-l-030", "prompt": "Write a detailed explanation of microservices architecture patterns.", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": null, "expected_format": null, "target_output_tokens": 500, "bucket": "long", "category": "long_form", "split": null, "metadata": null}
{"prompt_id": "bq-l-031", "prompt": "Explain the physics of how airplanes generate lift.", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": null, "expected_format": null, "target_output_tokens": 400, "bucket": "long", "category": "long_form", "split": null, "metadata": null}
{"prompt_id": "bq-l-032", "prompt": "Describe the differences between IPv4 and IPv6.", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": null, "expected_format": null, "target_output_tokens": 400, "bucket": "long", "category": "long_form", "split": null, "metadata": null}
{"prompt_id": "bq-l-033", "prompt": "Write a comprehensive overview of data normalization in databases.", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": null, "expected_format": null, "target_output_tokens": 500, "bucket": "long", "category": "long_form", "split": null, "metadata": null}
{"prompt_id": "bq-l-034", "prompt": "Explain how garbage collection works in programming languages.", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": null, "expected_format": null, "target_output_tokens": 500, "bucket": "long", "category": "long_form", "split": null, "metadata": null}
{"prompt_id": "bq-l-035", "prompt": "Describe the process of nuclear fission and fusion.", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": null, "expected_format": null, "target_output_tokens": 500, "bucket": "long", "category": "long_form", "split": null, "metadata": null}
{"prompt_id": "bq-l-036", "prompt": "Write a detailed guide to Prometheus metrics and alerting.", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": null, "expected_format": null, "target_output_tokens": 500, "bucket": "long", "category": "long_form", "split": null, "metadata": null}
{"prompt_id": "bq-l-037", "prompt": "Explain the principles behind load balancing algorithms.", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": null, "expected_format": null, "target_output_tokens": 500, "bucket": "long", "category": "long_form", "split": null, "metadata": null}
{"prompt_id": "bq-l-038", "prompt": "Describe how HTTPS and TLS handshake work.", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": null, "expected_format": null, "target_output_tokens": 500, "bucket": "long", "category": "long_form", "split": null, "metadata": null}
{"prompt_id": "bq-l-039", "prompt": "Write a comprehensive overview of design patterns: Singleton, Factory, Observer.", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": null, "expected_format": null, "target_output_tokens": 500, "bucket": "long", "category": "long_form", "split": null, "metadata": null}
{"prompt_id": "bq-l-040", "prompt": "Explain the MapReduce programming model with examples.", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": null, "expected_format": null, "target_output_tokens": 500, "bucket": "long", "category": "long_form", "split": null, "metadata": null}
{"prompt_id": "bq-l-041", "prompt": "Describe the structure and function of DNA replication.", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": null, "expected_format": null, "target_output_tokens": 500, "bucket": "long", "category": "long_form", "split": null, "metadata": null}
{"prompt_id": "bq-l-042", "prompt": "Write a detailed comparison of message queue systems: Kafka vs RabbitMQ.", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": null, "expected_format": null, "target_output_tokens": 500, "bucket": "long", "category": "long_form", "split": null, "metadata": null}
{"prompt_id": "bq-l-043", "prompt": "Explain how neural network attention mechanisms work in transformers.", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": null, "expected_format": null, "target_output_tokens": 500, "bucket": "long", "category": "long_form", "split": null, "metadata": null}
{"prompt_id": "bq-l-044", "prompt": "Describe the principles of ACID transactions in databases.", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": null, "expected_format": null, "target_output_tokens": 400, "bucket": "long", "category": "long_form", "split": null, "metadata": null}
{"prompt_id": "bq-l-045", "prompt": "Write a comprehensive overview of CI/CD best practices.", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": null, "expected_format": null, "target_output_tokens": 500, "bucket": "long", "category": "long_form", "split": null, "metadata": null}
{"prompt_id": "bq-l-046", "prompt": "Explain the concept of eventual consistency in distributed systems.", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": null, "expected_format": null, "target_output_tokens": 400, "bucket": "long", "category": "long_form", "split": null, "metadata": null}
{"prompt_id": "bq-l-047", "prompt": "Describe how WebSockets work compared to HTTP polling.", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": null, "expected_format": null, "target_output_tokens": 400, "bucket": "long", "category": "long_form", "split": null, "metadata": null}
{"prompt_id": "bq-l-048", "prompt": "Write a detailed explanation of container orchestration with Kubernetes.", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": null, "expected_format": null, "target_output_tokens": 500, "bucket": "long", "category": "long_form", "split": null, "metadata": null}
{"prompt_id": "bq-l-049", "prompt": "Explain the history and impact of Moore's Law.", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": null, "expected_format": null, "target_output_tokens": 400, "bucket": "long", "category": "long_form", "split": null, "metadata": null}
{"prompt_id": "bq-l-050", "prompt": "Describe the architecture of a modern web application from frontend to database.", "scenario_id": "benchmark-quant-v1", "dataset_id": "benchmark-quant", "expected_contains": null, "expected_format": null, "target_output_tokens": 500, "bucket": "long", "category": "long_form", "split": null, "metadata": null}
